{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from IPython.display import display\n",
    "from glob import glob\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "\n",
    "import altair as alt\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from pandas import read_csv, set_option, to_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path.cwd()\n",
    "sys.path.append(str(PROJECT_ROOT / \"pyviz_panel\" / \"app\" / \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport visualization_helpers_altair\n",
    "from visualization_helpers_altair import gen_choro_map, gen_heat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_option(\"display.max_rows\", 500)\n",
    "set_option(\"display.max_columns\", 500)\n",
    "set_option(\"display.width\", 1000)\n",
    "# alt.renderers.enable(\"default\")\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"toc\"></a>\n",
    "\n",
    "## [Table of Contents](#table-of-contents)\n",
    "0. [About](#about)\n",
    "1. [User Inputs](#user-inputs)\n",
    "2. [Load data](#load-data)\n",
    "3. [Generate choropleth maps](#generate-choropleth-maps)\n",
    "4. [Generate heatmaps](#generate-heatmaps)\n",
    "5. [Generate compound plots](#generate-compound-plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about\"></a>\n",
    "\n",
    "## 0. [About](#about)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use [Altair](https://altair-viz.github.io/) to generate the plots to be shown on a dashboard using the date-time and geographical data exported to `data/processed/heat_mapping_inputs.csv` and `data/processed/choro_mapping_inputs.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"user-inputs\"></a>\n",
    "\n",
    "## 1. [User Inputs](#user-inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define below the variables that are to be used throughout the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll specify the variabes that will be picked up from dashboard inputs. Next, we'll specify inputs related to the location of input and output files relevant to the dashboard. We'll then specify plotting preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "PROJECT_DIR = str(Path().cwd())  # type: Path\n",
    "data_dir = str(Path(PROJECT_DIR) / \"data\")\n",
    "dash_data_dir = str(Path(PROJECT_DIR) / \"aci-dash\" / \"app\" / \"data\")\n",
    "figs_dir = str(Path(PROJECT_DIR) / \"reports\" / \"figures\")\n",
    "\n",
    "choro_data_dir = str(Path(dash_data_dir) / \"processed\" / \"choro_mapping_inputs.csv\")\n",
    "heat_data_dir = str(Path(dash_data_dir) / \"processed\" / \"heat_mapping_inputs.csv\")\n",
    "\n",
    "primary_types = [\"CRIMINAL_DISTURBANCE\", \"VIOLENCE_TO_HUMAN\", \"PROPERTY_DAMAGE\"]\n",
    "da_choices = [\"district\"]  # \"beat\" (or \"district\"), \"community_area\"\n",
    "heatmap_dir_path = figs_dir\n",
    "choromap_dir_path = figs_dir\n",
    "\n",
    "pf = \"Police*\"\n",
    "ca = \"Community*\"\n",
    "nb = \"Neighborhoods\"\n",
    "da = {\n",
    "    \"neighbourhood\": {\n",
    "        # \"file\": glob(str(Path(data_dir) / \"raw\" / nb / \"*.shp\"))[0],\n",
    "        \"basic_view_cols\": \"pri|sec|geometry\",\n",
    "        \"pre-post-explosition-compare\": \"pri_neigh\",\n",
    "        \"left_join_col\": \"pri_neigh_x\",\n",
    "    },\n",
    "    \"district\": {  # \"beat\" or \"district\"\n",
    "        # \"file\": glob(str(Path(data_dir) / \"raw\" / pf / \"*.shp\"))[0],\n",
    "        \"basic_view_cols\": \"district|sect|geometry\",  # \"beat|sect|geometry\" or \"district|sect|geometry\"\n",
    "        \"pre-post-explosition-compare\": \"district\",  # \"beat\" or \"district\"\n",
    "        \"left_join_col\": \"district\",  # \"beat_num_x\" or \"district_x\"\n",
    "    },\n",
    "    \"community_area\": {\n",
    "        # \"file\": glob(str(Path(data_dir) / \"raw\" / ca / \"*.shp\"))[0],\n",
    "        \"basic_view_cols\": \"area_num_1|community|geometry\",\n",
    "        \"pre-post-explosition-compare\": \"comarea\",\n",
    "        \"left_join_col\": \"area_num_1_x\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# Plotting preferences\n",
    "agg_dict = {\"arrest\": [\"sum\"], \"datetime\": [\"count\"]}\n",
    "\n",
    "general_plot_specs = {\n",
    "    \"choromap_projectiontype\": \"mercator\",\n",
    "    \"color_by_column\": [\"datetime|count\"],\n",
    "    \"colorscheme\": \"yelloworangered\",\n",
    "    \"choro_map_figsize\": {\"width\": 400, \"height\": 600},\n",
    "    \"legend_title\": [\"Occurrences\"],\n",
    "    \"heatmap_xy\": {\"x\": \"month:O\", \"y\": \"day:O\", \"yscale\": \"linear\"},\n",
    "    \"heat_map_figsize\": {\"width\": 300, \"height\": 535},\n",
    "}\n",
    "\n",
    "dt_hmap = {\n",
    "    \"sum(datetime|count):Q\": {\n",
    "        \"title\": \"Occurrences\",\n",
    "        \"type\": \"quantitative\",\n",
    "        \"format\": \".2f\",\n",
    "    },\n",
    "    \"sum(arrest|sum):Q\": {\"title\": \"Arrests\", \"type\": \"quantitative\", \"format\": \".2f\"},\n",
    "    \"mean(probability_of_max_class|mean):Q\": {\n",
    "        \"title\": \"Probability (Avg.)\",\n",
    "        \"type\": \"quantitative\",\n",
    "        \"format\": \".2f\",\n",
    "    },\n",
    "}\n",
    "\n",
    "dt_choro = {\n",
    "    \"properties.sector\": {\"title\": \"Sector\", \"type\": \"nominal\"},\n",
    "    \"properties.beat_num\": {\"title\": \"Beat\", \"type\": \"nominal\"},\n",
    "    \"properties.area\": {\n",
    "        \"title\": \"Area (sq. km)\",\n",
    "        \"type\": \"quantitative\",\n",
    "        \"format\": \".2f\",\n",
    "    },\n",
    "    \"properties.datetime|count\": {\"title\": \"Ocurrences\", \"type\": \"quantitative\"},\n",
    "    \"properties.arrest|sum\": {\"title\": \"Arrests\", \"type\": \"quantitative\"},\n",
    "    \"properties.probability_of_max_class|mean\": {\n",
    "        \"title\": \"Probability (Avg.)\",\n",
    "        \"type\": \"quantitative\",\n",
    "        \"format\": \".2f\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if choro_data_dir == \"cloud\":\n",
    "    az_storage_container_name = \"myconedesx7\"\n",
    "    conn_str = (\n",
    "        \"DefaultEndpointsProtocol=https;\"\n",
    "        f\"AccountName={os.getenv('AZURE_STORAGE_ACCOUNT')};\"\n",
    "        f\"AccountKey={os.getenv('AZURE_STORAGE_KEY')};\"\n",
    "        f\"EndpointSuffix={os.getenv('ENDPOINT_SUFFIX')}\"\n",
    "    )\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(conn_str=conn_str)\n",
    "    choro_blob_client = blob_service_client.get_blob_client(\n",
    "        container=az_storage_container_name, blob=\"blobedesz4\"\n",
    "    )\n",
    "    choro_data_dir = StringIO(choro_blob_client.download_blob().content_as_text())\n",
    "    heat_blob_client = blob_service_client.get_blob_client(\n",
    "        container=az_storage_container_name, blob=\"blobedesz5\"\n",
    "    )\n",
    "    heat_data_dir = StringIO(heat_blob_client.download_blob().content_as_text())\n",
    "else:\n",
    "    da[\"neighbourhood\"][\"file\"] = glob(str(Path(data_dir) / \"raw\" / nb / \"*.shp\"))[0]\n",
    "    da[\"district\"][\"file\"] = glob(str(Path(data_dir) / \"raw\" / pf / \"*.shp\"))[0]\n",
    "    da[\"community_area\"][\"file\"] = glob(str(Path(data_dir) / \"raw\" / ca / \"*.shp\"))[0]\n",
    "    (choro_data_dir, heat_data_dir) = (\n",
    "        Path(choro_data_dir),\n",
    "        Path(heat_data_dir),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(heatmap_dir_path, choromap_dir_path) = [\n",
    "    Path(heatmap_dir_path),\n",
    "    Path(choromap_dir_path),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll programmatically assemble a list dictionaries to be used as for fields in Altair hover tooltips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tooltips_choro_map = []\n",
    "for da_choice in da_choices:\n",
    "    tooltip_field = da_choice if da_choice != \"community_area\" else \"community_x\"\n",
    "    tooltip_list = []\n",
    "    for k, v in dt_choro.items():\n",
    "        if \"format\" not in v:\n",
    "            tooltip_list.append({\"title\": v[\"title\"], \"field\": k, \"type\": v[\"type\"]})\n",
    "        else:\n",
    "            tooltip_list.append(\n",
    "                {\n",
    "                    \"title\": v[\"title\"],\n",
    "                    \"field\": k,\n",
    "                    \"type\": v[\"type\"],\n",
    "                    \"format\": v[\"format\"],\n",
    "                }\n",
    "            )\n",
    "    tooltip_list.insert(\n",
    "        0,\n",
    "        {\n",
    "            \"title\": f\"{da_choice.title()}\",\n",
    "            \"field\": f\"properties.{tooltip_field}\",\n",
    "            \"type\": \"nominal\",\n",
    "        },\n",
    "    )\n",
    "    tooltips_choro_map.append(tooltip_list)\n",
    "\n",
    "tooltip_hmap = [\n",
    "    alt.Tooltip(k, title=v[\"title\"], type=v[\"type\"], format=v[\"format\"])\n",
    "    for k, v in dt_hmap.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll define helper function to be used for\n",
    "- [setting Altair plotting styles](https://github.com/altair-viz/altair/issues/1021#issuecomment-406145719)\n",
    "- checking if a point (specified by its Latitude and Longitude) occurs inside a list of [Polygons](http://geopandas.org/data_structures.html#geoseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_cell():\n",
    "    return {\"config\": {\"style\": {\"cell\": {\"strokeOpacity\": 0}}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register the custom theme under a chosen name\n",
    "alt.themes.register(\"no_cell\", no_cell)\n",
    "# enable the newly registered theme\n",
    "alt.themes.enable(\"no_cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load-data\"></a>\n",
    "\n",
    "## 2. [Load data](#load-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by loading the two mapping files into separate `DataFrame`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch = read_csv(choro_data_dir)\n",
    "df_h = read_csv(heat_data_dir)\n",
    "# df_h[\"month\"] = to_datetime(df_h[\"month\"], format=\"%m\").dt.month_name()\n",
    "df_h[\"probability_of_max_class|mean\"] *= 100\n",
    "display(df_h.head())\n",
    "display(df_ch.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"generate-choropleth-maps\"></a>\n",
    "\n",
    "## 3. [Generate choropleth maps](#generate-choropleth-maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll generate each version of the choropleth map\n",
    "- one version per user specification for `primary_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = gen_choro_map(\n",
    "    primary_types=primary_types,\n",
    "    df_ch=df_ch,\n",
    "    da=da,\n",
    "    da_choices=da_choices,\n",
    "    tooltips_choro_map=tooltips_choro_map,\n",
    "    general_plot_specs=general_plot_specs,\n",
    "    figs_dir=figs_dir,\n",
    "    save_to_html=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display each version of the choropleth map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k, primary_type in enumerate(primary_types):\n",
    "    alt_maps = alt.hconcat(list(d.values())[k]).resolve_scale(color=\"independent\")\n",
    "    display(alt_maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"generate-heatmaps\"></a>\n",
    "\n",
    "## 4. [Generate heatmaps](#generate-heatmaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll generate each version of the datetime heatmap\n",
    "- one version per user specification for `primary_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = gen_heat_map(\n",
    "    x=general_plot_specs[\"heatmap_xy\"][\"x\"],\n",
    "    y=general_plot_specs[\"heatmap_xy\"][\"y\"],\n",
    "    yscale=general_plot_specs[\"heatmap_xy\"][\"yscale\"],\n",
    "    primary_types=primary_types,\n",
    "    df_h=df_h,\n",
    "    tooltip_hmap=tooltip_hmap,\n",
    "    general_plot_specs=general_plot_specs,\n",
    "    figs_dir=figs_dir,\n",
    "    save_to_html=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display each version of the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k, primary_type in enumerate(primary_types):\n",
    "    alt_maps = alt.hconcat(list(dh.values())[k]).resolve_scale(color=\"independent\")\n",
    "    display(alt_maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"generate-compound-plots\"></a>\n",
    "\n",
    "## 5. [Generate compound plots](#generate-compound-plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll generate each view of the pairs of plots to be displayed on the dashboard\n",
    "- one view per user specification for `primary_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for (_, choro_map), (_, heat_map) in zip(d.items(), dh.items()):\n",
    "    dash = alt.hconcat(choro_map, heat_map).resolve_scale(color=\"independent\")\n",
    "    display(dash)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
