{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Classification trials](#classification-trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from io import StringIO\n",
    "from IPython.display import display\n",
    "from os.path import getctime\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.model_runner\n",
    "from src.model_runner import sklearn_trials\n",
    "\n",
    "%aimport src.pipe_runner\n",
    "from src.pipe_runner import (\n",
    "    boosting_trials,\n",
    "    get_best_pipe_by_model_name,\n",
    "    get_best_naive_pipe_by_strategy_name,\n",
    "    get_preds_probas,\n",
    "    run_boosted_tuning,\n",
    "    get_feature_permutation_importances,\n",
    ")\n",
    "\n",
    "%aimport src.visualization_helpers\n",
    "from src.visualization_helpers import (\n",
    "    plot_horiz_bar,\n",
    "    plot_horizontal_box_plots,\n",
    "    show_confusion_matrix,\n",
    "    show_FeatureImportances,\n",
    ")\n",
    "\n",
    "%aimport src.inspection_helpers\n",
    "from src.inspection_helpers import get_preds_probas\n",
    "\n",
    "%aimport src.feature_helpers\n",
    "from src.feature_helpers import (\n",
    "    apply_over_under_sampling,\n",
    "    check_mapped_column_unique_values,\n",
    "    replace_col_values,\n",
    ")\n",
    "\n",
    "%aimport src.metrics_helpers\n",
    "from src.metrics_helpers import my_eval_metric\n",
    "\n",
    "%aimport src.export_outputs\n",
    "from src.export_outputs import (\n",
    "    export_experiment_results,\n",
    "    export_mapping_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 26\n",
    "MEDIUM_SIZE = 28\n",
    "BIGGER_SIZE = 30\n",
    "plt.rc(\"font\", size=SMALL_SIZE)  # controls default text sizes\n",
    "plt.rc(\"axes\", titlesize=SMALL_SIZE)  # fontsize of the axes title\n",
    "plt.rc(\"axes\", labelsize=MEDIUM_SIZE)  # fontsize of the x and y labels\n",
    "plt.rc(\"xtick\", labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
    "plt.rc(\"ytick\", labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
    "plt.rc(\"legend\", fontsize=SMALL_SIZE)  # legend fontsize\n",
    "plt.rc(\"figure\", titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "plt.rcParams[\"axes.facecolor\"] = \"white\"\n",
    "sns.set_style(\"darkgrid\", {\"legend.frameon\": False})\n",
    "sns.set_context(\"talk\", font_scale=0.95, rc={\"lines.linewidth\": 2.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"toc\"></a>\n",
    "\n",
    "## [Table of Contents](#table-of-contents)\n",
    "0. [About](#about)\n",
    "1. [User Inputs](#user-inputs)\n",
    "2. [Load joined data](#load-joined-data)\n",
    "3. [Exploratory Data Analysis and Feature Engineering](#exploratory-data-analysis-and-feature-engineering)\n",
    "4. [Re-grouping categorical features](#re-grouping-categorical-features)\n",
    "5. [Pre-processing categorical features](#pre-processing-categorical-features)\n",
    "6. [Generate training and testing splits](#generate-training-and-testing-splits)\n",
    "7. [Pre-processing numerical features](#pre-processing-numerical-features)\n",
    "8. [Experiments in modeling](#experiments-in-modeling)\n",
    "9. [Gradient Boosting trials](#gradient-boosting-trials)\n",
    "10. [Plot model comparison](#plot-model-comparison)\n",
    "12. [Export experiment outputs](#export-experiment-outputs)\n",
    "13. [Export data for mapping](#export-data-for-mapping)\n",
    "13. [Examine feature importances](#examine-feature-importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about\"></a>\n",
    "\n",
    "## 0. [About](#about)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will experiment with classification models on the joined Chicago crime listings-weather-demographics data in `data/processed/all_joined__mmddyyyy_HHMMss.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"user-inputs\"></a>\n",
    "\n",
    "## 1. [User Inputs](#user-inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define below the variables and helper functions that are to be used throughout the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "data_dir_path = str(Path().cwd() / \"data\" / \"processed\")\n",
    "dash_data_dir_path = str(Path().cwd() / \"aci-dash\" / \"app\" / \"data\" / \"processed\")\n",
    "cloud_data = \"no\"\n",
    "figs_dir_path = str(Path().cwd() / \"reports\" / \"figures\")\n",
    "d_mapping_specs = {\n",
    "    \"choro\": [\n",
    "        [\"primary_type\", \"district\"],\n",
    "        {\n",
    "            \"arrest\": [\"sum\"],\n",
    "            \"datetime\": [\"count\"],\n",
    "            \"total_population\": [\"sum\"],\n",
    "            \"median_household_value\": [\"mean\"],\n",
    "            \"median_household_income\": [\"mean\"],\n",
    "            \"probability_of_max_class\": [\"mean\"],\n",
    "        },\n",
    "        str(Path(dash_data_dir_path) / \"choro_mapping_inputs.csv\"),\n",
    "    ],\n",
    "    \"heatmap\": [\n",
    "        [\"primary_type\", \"day\", \"month\"],\n",
    "        {\n",
    "            \"arrest\": [\"sum\"],\n",
    "            \"datetime\": [\"count\"],\n",
    "            \"TAVG\": [\"mean\"],\n",
    "            \"SNOW\": [\"mean\"],\n",
    "            \"probability_of_max_class\": [\"mean\"],\n",
    "        },\n",
    "        str(Path(dash_data_dir_path) / \"heat_mapping_inputs.csv\"),\n",
    "    ],\n",
    "}\n",
    "\n",
    "experiment_summary_data_path = str(\n",
    "    Path(dash_data_dir_path)\n",
    "    / f\"experiment_summary_{datetime.now().strftime('%Y%m%d-%H%M%S')}.csv\"\n",
    ")\n",
    "experiment_all_cv_data_path = str(\n",
    "    Path(data_dir_path)\n",
    "    / f\"experiment_all_cv_{datetime.now().strftime('%Y%m%d-%H%M%S')}.csv\"\n",
    ")\n",
    "\n",
    "scoring_metric = \"accuracy\"\n",
    "n_folds = 5\n",
    "target = \"primary_type\"\n",
    "top_n_features_to_visualize = 10\n",
    "\n",
    "use_boosting_classifiers = False\n",
    "boosting_classifier_names = [\"LGBMClassifier\", \"XGBClassifier\"]\n",
    "\n",
    "years_wanted = [2018, 2019]\n",
    "months_wanted = [1, 2, 3]\n",
    "non_location_col_choices = {\n",
    "    0: [\"dayofyear\", \"hour\", \"location_description\", target],\n",
    "    1: [\"month\", \"day\", \"hour\", \"location_description\", target],\n",
    "    2: [\"month\", \"weekday_name\", \"hour\", \"location_description\", target],\n",
    "    3: [\"weekofyear\", \"weekday_name\", \"hour\", \"location_description\", target],\n",
    "    4: [\"year\", \"month\", \"is_weekend\", \"is_dark\", \"location_description\", target],\n",
    "}\n",
    "chosen_non_location_cols = non_location_col_choices[4]\n",
    "features_to_consolidate = [\"location_description\", \"community_area\", \"primary_type\"]\n",
    "\n",
    "nums = [\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"total_population\",\n",
    "    \"median_household_income\",\n",
    "    # \"occupied_housing_values\",\n",
    "    \"median_household_value\",\n",
    "    \"TAVG\",\n",
    "    \"AWND\",\n",
    "    \"PRCP\",\n",
    "    \"SNOW\",\n",
    "]\n",
    "cats = [\n",
    "    \"district\",\n",
    "    # \"fbi_code\",\n",
    "    # \"ward\",\n",
    "    # \"beat\",\n",
    "    \"community_area\",  # transformed to Side\n",
    "    \"arrest\",\n",
    "    \"domestic\",\n",
    "] + chosen_non_location_cols[:-1]\n",
    "\n",
    "target_balance = \"Unbalanced\"  # \"under_sampled\", \"over_sampled\" or \"Unbalanced\"\n",
    "\n",
    "# Mapping dictionaries\n",
    "d_comm_area_to_side = {\n",
    "    \"Central\": [8, 32, 33],\n",
    "    \"North\": [5, 6, 7, 21, 22],\n",
    "    \"Far North\": [1, 2, 3, 4, 9, 10, 11, 12, 13, 14, 76, 77],\n",
    "    \"Northwest\": [15, 16, 17, 18, 19, 20],\n",
    "    \"West\": [23, 24, 25, 26, 27, 28, 29, 30, 31],\n",
    "    \"South\": [34, 35, 36, 38, 39, 40, 41, 42, 43, 60, 69],\n",
    "    \"Southwest\": [56, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68],\n",
    "    \"Far Southeast\": [44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55],\n",
    "    \"Far Southwest\": [70, 71, 72, 73, 74, 75],\n",
    "}\n",
    "\n",
    "# # Groupings that were used in most of the development\n",
    "# d_pri_type = {\n",
    "#     \"A\": [\n",
    "#         \"THEFT\",\n",
    "#         \"BURGLARY\",\n",
    "#         \"ROBBERY\",\n",
    "#         \"MOTOR VEHICLE THEFT\",\n",
    "#         \"CRIMINAL DAMAGE\",\n",
    "#         \"CRIMINAL TRESPASS\",\n",
    "#         \"ARSON\",\n",
    "#     ],\n",
    "#     \"B\": [\n",
    "#         \"BATTERY\",\n",
    "#         \"ASSAULT\",\n",
    "#         \"KIDNAPPING\",\n",
    "#         \"HOMICIDE\",\n",
    "#         \"CRIM SEXUAL ASSAULT\",\n",
    "#         \"SEX OFFENSE\",\n",
    "#         \"HUMAN TRAFFICKING\",\n",
    "#         \"OFFENSE INVOLVING CHILDREN\",\n",
    "#         \"STALKING\",\n",
    "#         \"INTIMIDATION\",\n",
    "#         \"PUBLIC INDECENCY\",\n",
    "#         \"PROSTITUTION\",\n",
    "#     ],\n",
    "#     \"D\": [\n",
    "#         \"DECEPTIVE PRACTICE\",\n",
    "#         \"OTHER OFFENSE\",\n",
    "#         \"WEAPONS VIOLATION\",\n",
    "#         \"CONCEALED CARRY LICENSE VIOLATION\",\n",
    "#         \"PUBLIC PEACE VIOLATION\",\n",
    "#         \"OBSCENITY\",\n",
    "#         \"INTERFERENCE WITH PUBLIC OFFICER\",\n",
    "#         \"LIQUOR LAW VIOLATION\",\n",
    "#         \"NARCOTICS\",\n",
    "#         \"GAMBLING\",\n",
    "#         \"NON-CRIMINAL\",\n",
    "#     ],\n",
    "# }\n",
    "\n",
    "# Groupings that are closest possible match to Crime Topic Modeling paper:\n",
    "# https://link.springer.com/content/pdf/10.1186%2Fs40163-017-0074-0.pdf\n",
    "d_pri_type = {\n",
    "    \"PROPERTY_DAMAGE\": [\n",
    "        \"THEFT\",\n",
    "        \"BURGLARY\",\n",
    "        \"CRIMINAL TRESPASS\",\n",
    "        \"ARSON\",  # originally RED\n",
    "        \"MOTOR VEHICLE THEFT\",  # originally RED\n",
    "        \"CRIMINAL DAMAGE\",  # originally RED\n",
    "    ],  # A (PURPLE)\n",
    "    \"VIOLENCE_TO_HUMAN\": [  # B (YELLOW)\n",
    "        \"BATTERY\",\n",
    "        \"ASSAULT\",\n",
    "        \"KIDNAPPING\",\n",
    "        \"HOMICIDE\",\n",
    "        \"CRIM SEXUAL ASSAULT\",  # I considered to be more serious human-related crime\n",
    "        \"SEX OFFENSE\",  # ? I considered to be more serious human-related crime\n",
    "        \"HUMAN TRAFFICKING\",  # ? I considered to be more serious human-related crime\n",
    "        \"PROSTITUTION\",  # ? I considered to be more serious human-related crime\n",
    "        \"ROBBERY\",\n",
    "        \"INTERFERENCE WITH PUBLIC OFFICER\",\n",
    "        \"WEAPONS VIOLATION\",\n",
    "        \"CONCEALED CARRY LICENSE VIOLATION\",\n",
    "    ],\n",
    "    \"CRIMINAL_DISTURBANCE\": [  # D (GREEN)\n",
    "        \"STALKING\",\n",
    "        \"INTIMIDATION\",\n",
    "        # \"PUBLIC INDECENCY\",\n",
    "        \"OFFENSE INVOLVING CHILDREN\",\n",
    "        \"DECEPTIVE PRACTICE\",\n",
    "        \"OTHER OFFENSE\",  # I considered this to be OTHER MISCELLANEOUS CRIME\n",
    "        \"PUBLIC PEACE VIOLATION\",\n",
    "        \"OBSCENITY\",\n",
    "        \"LIQUOR LAW VIOLATION\",  # ?\n",
    "        \"NARCOTICS\",  # ?\n",
    "        \"GAMBLING\",  # ?\n",
    "        \"NON-CRIMINAL\",  # I considered this to be OTHER MISCELLANEOUS CRIME\n",
    "    ],\n",
    "    # \"VEHICLE AND PROPERTY DAMAGE\": [\"ARSON\", \"MOTOR VEHICLE THEFT\", \"CRIMINAL DAMAGE\",],  # E (RED)\n",
    "}\n",
    "\n",
    "d_loc_desc = {\n",
    "    \"Public_Accessible\": [\n",
    "        \"STREET\",\n",
    "        \"SIDEWALK\",\n",
    "        \"ALLEY\",\n",
    "        \"PARK PROPERTY\",\n",
    "        \"HIGHWAY/EXPRESSWAY\",\n",
    "        \"BRIDGE\",\n",
    "        # \"GANGWAY\",\n",
    "        \"PORCH\",\n",
    "        \"HALLWAY\",\n",
    "        \"HOTEL\",\n",
    "    ],\n",
    "    \"Dining_Shopping\": [\n",
    "        \"RESTAURANT\",\n",
    "        \"DEPARTMENT STORE\",\n",
    "        \"GROCERY FOOD STORE\",\n",
    "        \"SMALL RETAIL STORE\",\n",
    "        \"BAR OR TAVERN\",\n",
    "        \"TAVERN/LIQUOR STORE\",\n",
    "        \"CONVENIENCE STORE\",\n",
    "        \"APPLIANCE STORE\",\n",
    "        \"PAWN SHOP\",\n",
    "        \"RETAIL STORE\",\n",
    "    ],\n",
    "    \"Private_Housing\": [\n",
    "        \"RESIDENCE\",\n",
    "        \"APARTMENT\",\n",
    "        \"RESIDENCE PORCH/HALLWAY\",\n",
    "        \"RESIDENTIAL YARD (FRONT/BACK)\",\n",
    "        \"RESIDENCE-GARAGE\",\n",
    "        \"HOTEL/MOTEL\",\n",
    "        \"CHA APARTMENT\",\n",
    "        \"DRIVEWAY - RESIDENTIAL\",\n",
    "        \"CHA PARKING LOT/GROUNDS\",\n",
    "        \"CHA HALLWAY/STAIRWELL/ELEVATOR\",\n",
    "        \"HOUSE\",\n",
    "        \"KENNEL\",\n",
    "        \"BASEMENT\",\n",
    "        \"YARD\",\n",
    "    ],\n",
    "    \"Transport\": [\n",
    "        \"VEHICLE NON-COMMERCIAL\",\n",
    "        \"TAXICAB\",\n",
    "        \"VEHICLE - OTHER RIDE SHARE SERVICE (E.G., UBER, LYFT)\",\n",
    "        \"VEHICLE-COMMERCIAL\",\n",
    "        \"OTHER RAILROAD PROP / TRAIN DEPOT\",\n",
    "        \"OTHER COMMERCIAL TRANSPORTATION\",\n",
    "        \"VEHICLE - DELIVERY TRUCK\",\n",
    "        \"VEHICLE-COMMERCIAL - ENTERTAINMENT/PARTY BUS\",\n",
    "        \"VEHICLE-COMMERCIAL - TROLLEY BUS\",\n",
    "    ],\n",
    "    \"Business_Academic\": [\n",
    "        \"SCHOOL, PUBLIC, BUILDING\",\n",
    "        \"COMMERCIAL / BUSINESS OFFICE\",\n",
    "        \"BANK\",\n",
    "        \"CURRENCY EXCHANGE\",\n",
    "        \"ATM (AUTOMATIC TELLER MACHINE)\",\n",
    "        \"SCHOOL, PUBLIC, GROUNDS\",\n",
    "        \"SCHOOL, PRIVATE, BUILDING\",\n",
    "        \"LIBRARY\",\n",
    "        \"MOVIE HOUSE/THEATER\",\n",
    "        \"COLLEGE/UNIVERSITY GROUNDS\",\n",
    "        \"SCHOOL, PRIVATE, GROUNDS\",\n",
    "        \"COLLEGE/UNIVERSITY RESIDENCE HALL\",\n",
    "        \"SAVINGS AND LOAN\",\n",
    "        \"CLEANING STORE\",\n",
    "        \"CREDIT UNION\",\n",
    "        \"NEWSSTAND\",\n",
    "    ],\n",
    "    \"CTA\": [\n",
    "        \"CTA TRAIN\",\n",
    "        \"CTA STATION\",\n",
    "        \"CTA PLATFORM\",\n",
    "        \"CTA BUS\",\n",
    "        \"CTA BUS STOP\",\n",
    "        \"CTA GARAGE / OTHER PROPERTY\",\n",
    "        \"CTA TRACKS - RIGHT OF WAY\",\n",
    "    ],\n",
    "    \"Medical\": [\n",
    "        \"HOSPITAL BUILDING/GROUNDS\",\n",
    "        \"DRUG STORE\",\n",
    "        \"NURSING HOME/RETIREMENT HOME\",\n",
    "        \"MEDICAL/DENTAL OFFICE\",\n",
    "        \"DAY CARE CENTER\",\n",
    "        \"ANIMAL HOSPITAL\",\n",
    "    ],\n",
    "    \"Government\": [\n",
    "        \"POLICE FACILITY/VEH PARKING LOT\",\n",
    "        \"GOVERNMENT BUILDING/PROPERTY\",\n",
    "        \"FEDERAL BUILDING\",\n",
    "        \"JAIL / LOCK-UP FACILITY\",\n",
    "        \"FIRE STATION\",\n",
    "        \"GOVERNMENT BUILDING\",\n",
    "    ],\n",
    "    \"Religious\": [\"CHURCH/SYNAGOGUE/PLACE OF WORSHIP\", \"CEMETARY\"],\n",
    "    \"Leisure\": [\n",
    "        \"ATHLETIC CLUB\",\n",
    "        \"BARBERSHOP\",\n",
    "        \"SPORTS ARENA/STADIUM\",\n",
    "        \"POOL ROOM\",\n",
    "        \"BOWLING ALLEY\",\n",
    "        \"COIN OPERATED MACHINE\",\n",
    "        \"YMCA\",\n",
    "    ],\n",
    "    \"Manufacturing_Vacant\": [\n",
    "        \"VACANT LOT/LAND\",\n",
    "        \"CONSTRUCTION SITE\",\n",
    "        \"ABANDONED BUILDING\",\n",
    "        \"WAREHOUSE\",\n",
    "        \"FACTORY/MANUFACTURING BUILDING\",\n",
    "        \"VACANT LOT\",\n",
    "        \"OTHER\",\n",
    "    ],\n",
    "    \"AutoCareSales\": [\n",
    "        \"GAS STATION\",\n",
    "        \"CAR WASH\",\n",
    "        \"AUTO / BOAT / RV DEALERSHIP\",\n",
    "        \"AUTO\",\n",
    "        \"BOAT/WATERCRAFT\",\n",
    "        \"GARAGE/AUTO REPAIR\",\n",
    "        \"PARKING LOT\",\n",
    "        \"PARKING LOT/GARAGE(NON.RESID.)\",\n",
    "    ],\n",
    "    \"AIRPORT\": [\n",
    "        \"AIRPORT VENDING ESTABLISHMENT\",\n",
    "        \"AIRPORT EXTERIOR - SECURE AREA\",\n",
    "        \"AIRPORT BUILDING NON-TERMINAL - NON-SECURE AREA\",\n",
    "        \"AIRPORT PARKING LOT\",\n",
    "        \"AIRPORT BUILDING NON-TERMINAL - SECURE AREA\",\n",
    "        \"AIRPORT TERMINAL LOWER LEVEL - SECURE AREA\",\n",
    "        \"AIRCRAFT\",\n",
    "        \"AIRPORT EXTERIOR - NON-SECURE AREA\",\n",
    "        \"AIRPORT TERMINAL UPPER LEVEL - NON-SECURE AREA\",\n",
    "        \"AIRPORT TRANSPORTATION SYSTEM (ATS)\",\n",
    "    ],\n",
    "    \"PARKS\": [\"LAKEFRONT/WATERFRONT/RIVERBANK\", \"FOREST PRESERVE\", \"FARM\"],\n",
    "}\n",
    "\n",
    "model_params = {}\n",
    "model_params[\"DummyClassifier__most_frequent\"] = {\n",
    "    \"strategy\": \"most_frequent\",\n",
    "}\n",
    "model_params[\"DummyClassifier__uniform\"] = {\n",
    "    \"strategy\": \"uniform\",\n",
    "}\n",
    "model_params[\"DummyClassifier__stratified\"] = {\n",
    "    \"strategy\": \"stratified\",\n",
    "}\n",
    "model_params[\"LogisticRegression\"] = {\n",
    "    \"penalty\": \"l1\",\n",
    "    \"multi_class\": \"ovr\",\n",
    "    \"solver\": \"liblinear\",\n",
    "    \"class_weight\": \"balanced\",\n",
    "    \"max_iter\": 5000,\n",
    "}\n",
    "model_params[\"LinearSVC\"] = {\n",
    "    \"class_weight\": \"balanced\",\n",
    "    \"max_iter\": 1000,\n",
    "}\n",
    "model_params[\"GaussianNB\"] = {}\n",
    "model_params[\"RandomForestClassifier\"] = {\n",
    "    \"n_estimators\": 1500,\n",
    "    \"class_weight\": \"balanced\",\n",
    "    \"max_depth\": 10,\n",
    "    \"n_jobs\": -1,\n",
    "    \"random_state\": 0,\n",
    "}\n",
    "\n",
    "sklearn_wanted_classifiers = [\"LogisticRegression\", \"GaussianNB\"]\n",
    "dummy_strategies = [\"most_frequent\", \"uniform\", \"stratified\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cloud_data != \"yes\":\n",
    "    data_dir_path = Path(data_dir_path)\n",
    "    comb_data_filepath = max(\n",
    "        glob(str(data_dir_path / \"all_joined__*.csv\")), key=getctime\n",
    "    )\n",
    "    save_pref = True\n",
    "else:\n",
    "    az_storage_container_name = \"myconedesx7\"\n",
    "    blob_service = BlockBlobService(\n",
    "        account_name=os.environ.get(\"AZURE_STORAGE_ACCOUNT\"),\n",
    "        account_key=os.environ.get(\"AZURE_STORAGE_KEY\"),\n",
    "    )\n",
    "    comb_data_filepath = StringIO(\n",
    "        blob_service.get_blob_to_text(\n",
    "            container_name=az_storage_container_name, blob_name=\"blobedesz1\"\n",
    "        ).content\n",
    "    )\n",
    "    save_pref = False\n",
    "(\n",
    "    figs_dir_path,\n",
    "    # joined_data_file_path,\n",
    "    d_mapping_specs[\"choro\"][-1],\n",
    "    d_mapping_specs[\"heatmap\"][-1],\n",
    "    experiment_summary_data_path,\n",
    "    experiment_all_cv_data_path,\n",
    ") = [\n",
    "    Path(figs_dir_path),\n",
    "    # Path(joined_data_file_path),\n",
    "    Path(d_mapping_specs[\"choro\"][-1]),\n",
    "    Path(d_mapping_specs[\"heatmap\"][-1]),\n",
    "    Path(experiment_summary_data_path),\n",
    "    Path(experiment_all_cv_data_path),\n",
    "]\n",
    "sk_folds = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load-joined-data\"></a>\n",
    "\n",
    "## 2. [Load joined data](#load-joined-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by loading the joined data into a `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(comb_data_filepath, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll filter the data to only include the\n",
    "- years 2018 and 2019\n",
    "- months of December, January, February and March"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[\"year\"].isin(years_wanted)) & (df[\"month\"].isin(months_wanted))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exploratory-data-analysis-and-feature-engineering\"></a>\n",
    "\n",
    "## 3. [Exploratory Data Analysis and Feature Engineering](#exploratory-data-analysis-and-feature-engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll count the unique of the class labels and various categorical columns in the joined data\n",
    "- columns that were included in the crime listings data\n",
    "  - `district`\n",
    "  - `ward`\n",
    "  - `community_area`\n",
    "  - `fbi_code`\n",
    "  - `description`\n",
    "  - `location_description`\n",
    "- columns that were appended from the [Chicago open data portal](https://data.cityofchicago.org/browse?limitTo=datasets)\n",
    "  - [`neighbourhood`](https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Boundaries-Neighborhoods/9wp7-iasj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    pd.DataFrame(\n",
    "        df[\n",
    "            [\n",
    "                \"district\",\n",
    "                \"ward\",\n",
    "                \"community_area\",\n",
    "                \"fbi_code\",\n",
    "                \"description\",\n",
    "                \"beat\",\n",
    "                \"location_description\",\n",
    "                \"neighbourhood\",\n",
    "                \"primary_type\",\n",
    "            ]\n",
    "        ].nunique(),\n",
    "        columns=[\"num_unique_values\"],\n",
    "    ).sort_values(by=[\"num_unique_values\"], ascending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking ahead to how we would want to visualize this data, six of these features (excluding those containing description information - `location_description` and `description`) may be used for this purpose. We can find boundary files for the following features on the city's open data portal and would allow us to visualize crime by each of these grographical areas within the city, by coloring within the boundaries based on occurrences or arrests there\n",
    "- [`neighborhood`](https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Boundaries-Neighborhoods/bbvz-uum9)\n",
    "- [`district` (or sector) and `beat`](https://data.cityofchicago.org/Public-Safety/Boundaries-Police-Beats-current-/aerh-rz74)\n",
    "- [`community_area`](https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Boundaries-Community-Areas-current-/cauq-8yn6#Export)\n",
    "\n",
    "Additionally, we can [map **Side** of Chicago to its Community Areas](https://en.wikipedia.org/wiki/Community_areas_in_Chicago#Community_areas_by_side) by the community area identifier. Unfortunately, a bounddary file for side of the city is not available. This means we can map community areas but visualize crime by side of the city, which would potentially result in multiple community ares being assigned the same color since they fall within the same side.\n",
    "\n",
    "Boundary files are not available for `ward` so, analogous to `Side`, we would map one of the other types of geographic areas (eg. `neighborhood`s) but color by `ward` such that multiple areas (eg. multiple `neighborhood`s) would have the same color since they fall within the same `ward`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using any of the two `description`-based categorical features (`X`), we'll try to transform them by grouping them further. We'll do the same for the `primary_type` (these are the class labels, `y`). The benefit of applying such a transformation are\n",
    "- features (`X`)\n",
    "  - fewer one-hot encoded features will be eventually be produced\n",
    "- class labels (`y`)\n",
    "  - we will not be trying to predict class labels that occur infrequently throughout the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"re-grouping-categorical-features\"></a>\n",
    "\n",
    "## 4. [Re-grouping categorical features](#re-grouping-categorical-features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by discussing three of the dictionaries above that will be used to combine categorical features (`X`s), including the class labels (`y`s), into larger groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each dictionary, the key represents the new larger group name to be assigned.\n",
    "\n",
    "The dictionary to preform this grouping for the class labels is `d_pri_type` and two versions of this dictionary are shown. In the first (commented) version, a large number of groupings are created. This results in some groups having a small number of observations, while others have a large number. This making it [difficult for the classifier to predict labels for both groups](https://www.researchgate.net/post/Machine_learning_if_proportion_of_number_of_cases_in_different_class_in_training_set_matters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, d in zip(\n",
    "    features_to_consolidate, [d_loc_desc, d_comm_area_to_side, d_pri_type],\n",
    "):\n",
    "    print(\n",
    "        c, df[c].value_counts().shape[0], len([i for q in list(d.values()) for i in q])\n",
    "    )\n",
    "    print(\n",
    "        list(\n",
    "            set(df[c].value_counts().index.tolist())\n",
    "            - set([i for q in list(d.values()) for i in q])\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before replacing categories by larger groups using the mapping dictionaries, we'll use a helper function to verify that our mapping dictionary replaces all the unique values in the corresponding column of the `DataFrame` containing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll run this helper function over all features that we want to consolidate into larger groups in order to check that we have included all unique values in the feature in our mapping dictionary's values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_replacements = dict(\n",
    "    list(zip(features_to_consolidate, [d_loc_desc, d_comm_area_to_side, d_pri_type]))\n",
    ")\n",
    "\n",
    "for col_to_check, map_dict in zip(\n",
    "    features_to_consolidate, [d_loc_desc, d_comm_area_to_side, d_pri_type]\n",
    "):\n",
    "    check_mapped_column_unique_values(\n",
    "        df=df, colname=col_to_check, mapping_dict=map_dict\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use a helper function to preform this replacement. The function will map lists in the above dictionaries' keys to `DataFrame` columns. This will replace the current value of the column with the name of a larger group specified by the dictionary key corresponding to the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use this helper function to make the replacements in order to consolidate the unique values in all required columns into larger groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column, dict_replacements in col_replacements.items():\n",
    "    replace_col_values(df=df, col2map=column, replacement_dict=dict_replacements)\n",
    "    display(pd.DataFrame(df[column].value_counts(normalize=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the resulting number of unique values for each column that was mapped is smaller than that in the raw data, as expected. The number of observations in each of the newly assigned groups will not vary as much as in the original groupings. [One-hot encoding](https://en.wikipedia.org/wiki/One-hot) will now generate a smaller number of features than it would on the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_horiz_bar(\n",
    "    df,\n",
    "    col_name=\"primary_type\",\n",
    "    ptitle=\"Classes of Crime (categorized)\",\n",
    "    xspacer=0.01,\n",
    "    yspacer=0.4,\n",
    "    fig_size=(8, 3),\n",
    "    savefig=figs_dir_path,\n",
    "    save_pref=save_pref,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    pd.DataFrame(df[nums + cats].isna().sum(), columns=[\"number_of_missing_values\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pre-processing-categorical-features\"></a>\n",
    "\n",
    "## 5. [Pre-processing categorical features](#pre-processing-categorical-features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will perform one hot encoding on all selected categorical features in the `cats` list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will define variables for `X` (features) and `y` (class labels) to be used in modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, nums + cats].copy()\n",
    "y = df[target]\n",
    "display(X.head())\n",
    "pd.DataFrame(y).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll calculate the number of unique one-hot encoded features, across all categorical features, that will be generated by this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_cats_cols = X[cats].apply(pd.Series.value_counts).count().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will perform the one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = pd.get_dummies(X[cats].astype(str), prefix_sep=\"=\")\n",
    "X = pd.concat([X, dummy], axis=1)\n",
    "X = X.drop(cats, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll verify that the one-hot encoding has resulted in a `DataFrame` with the expected number of features calculated two steps above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    X.shape[1] == len(nums) + expected_cats_cols\n",
    "), \"mismatch in expected number of OHE cols\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"generate-training-and-testing-splits\"></a>\n",
    "\n",
    "## 6. [Generate training and testing splits](#generate-training-and-testing-splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will generate training, validation and testing splits of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape[0], X_train.shape[0] + X_val.shape[0] + X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll apply under-sampling, over-sampling or no re-sampling, as was specified earlier in the user inputs section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled, y_train_resampled = apply_over_under_sampling(\n",
    "    X_train=X_train, y_train=y_train, target_balance=target_balance,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll compare the number of rows in the testing, training and resampled training splits of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape[0], X_train.shape[0], X_train_resampled.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pre-processing-numerical-features\"></a>\n",
    "\n",
    "## 7. [Pre-processing numerical features](#pre-processing-numerical-features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will perform pre-processing needed for the modeling process. Since we previously did this for the categorical features (one-hot encoding of all features in the `cats` list), pre-processing will only be performed on the numerical features and will be done inside a `sklearn` pipeline object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericals_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"num\", numericals_transformer, nums)], remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"experiments-in-modeling\"></a>\n",
    "\n",
    "## 8. [Experiments in modeling](#experiments-in-modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use various models to separately predict the class labels. Each such run will constitute a single experiment, based on the inputs specified earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll assemble lists of instantiated models (classifiers) and model names, including `sklearn`'s [`DummyClassifier`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.dummy) which will provide baseline performance against which the predictive ability of more sophisticated models will be compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_classifiers = []\n",
    "dummy_names = []\n",
    "for strategy in dummy_strategies:\n",
    "    dummy_classifiers.append(\n",
    "        DummyClassifier(**model_params[\"DummyClassifier__\" + strategy])\n",
    "    )\n",
    "    dummy_names.append(f\"DummyClassifier__{strategy}\")\n",
    "\n",
    "sklearn_all_classifiers = {\n",
    "    \"LogisticRegression\": LogisticRegression(**model_params[\"LogisticRegression\"]),\n",
    "    \"LinearSVC\": LinearSVC(**model_params[\"LinearSVC\"]),\n",
    "    \"GaussianNB\": GaussianNB(**model_params[\"GaussianNB\"]),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(\n",
    "        **model_params[\"RandomForestClassifier\"]\n",
    "    ),\n",
    "}\n",
    "\n",
    "models = dummy_classifiers + [\n",
    "    sklearn_all_classifiers[k] for k in sklearn_wanted_classifiers\n",
    "]\n",
    "model_names = dummy_names + [type(model).__name__ for model in models[3:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use two helper functions to perform [KFCV](https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation) using a single model on training data, and return training and validation scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also use a helper function to calclate the class-based prediction accuracy from a [normalized confusion matrix](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#confusion-matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use each model from the above list to\n",
    "\n",
    "1. perform KFCV on training data (if possible)\n",
    "2. predict+score on validation and testing data\n",
    "3. generate evaluations for each model's performance on the out-of-sample (testing) data, with results\n",
    "   - stored in a DataFrame\n",
    "   - visualized in plots\n",
    "4. Plot all KFCV scores on single box plot, for all models\n",
    "5. Print a normalized confusion matrix\n",
    "\n",
    "All the above functionality will be wrapped into a helper function. This will serve as a comparison of multiple models' performance at predicting the type (category) of crime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "print(f\"Cell execution start time {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "df_sc, df_sc_all, pipes_all = sklearn_trials(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_train_resampled=X_train_resampled,\n",
    "    y_train_resampled=y_train_resampled,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    preprocessor=preprocessor,\n",
    "    nums=nums,\n",
    "    scoring_metric=scoring_metric,\n",
    "    models=models,\n",
    "    model_names=model_names,\n",
    "    sk_folds=sk_folds,\n",
    "    target_balance=target_balance,\n",
    "    dummy_names=dummy_names,\n",
    "    show_diagnostic_plots=False,\n",
    "    figs_dir_path=figs_dir_path,\n",
    ")\n",
    "\n",
    "print(f\"\\nCell execution end time {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gradient-boosting-trials\"></a>\n",
    "\n",
    "## 9. [Gradient Boosting trials](#gradient-boosting-trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will *explore* the capability of using [Gradient Boosting](https://en.wikipedia.org/wiki/Gradient_boosting) on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try out the [`xgboost`](https://xgboost.readthedocs.io/en/latest/index.html#) and [`lightgbm`](https://github.com/microsoft/LightGBM) open-source libraries here to compute `f1_score`s and compare to the other machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll use a helper function to train `xgboost` on training data and evaluate on validation data (starting from the one-hot encoded version of the features `X` and labels `y`). We will perform the following\n",
    "1. generate train-validation-test splits\n",
    "2. encode the class labels using `LabelEncoder`\n",
    "3. train the model using the training split\n",
    "4. Get the score on validation and testing splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use this helper function to\n",
    "1. train the model on the training data and provide the above-created validation set for model evaluation using the `eval_set` model hyperparameter\n",
    "2. calculate the average evaluation metric on the testing data\n",
    "   - since the model was trained using `eval_set`, which was the validation set, we will **only** calculate the average score on the test split of the data\n",
    "\n",
    "\n",
    "We will also generate some classification visualizations for the trained model, using testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "print(f\"Cell execution start time {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "if use_boosting_classifiers:\n",
    "    df_sc, df_sc_all = boosting_trials(\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_val=X_val,\n",
    "        y_val=y_val,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        boosting_classifier_names=boosting_classifier_names,\n",
    "        scoring_metric=scoring_metric,\n",
    "        df_sc=df_sc,\n",
    "        df_sc_all=df_sc_all,\n",
    "        show_diagnostic_plots=False,\n",
    "        save_pref=save_pref,\n",
    "    )\n",
    "\n",
    "print(f\"\\nCell execution end time {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plot-model-comparison\"></a>\n",
    "\n",
    "## 10. [Plot model comparison](#plot-model-comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll compare models used in a horizontal box plot\n",
    "- red filled circles will show the score on out-of-sample data (that was not used to train the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_sc_all\n",
    "except NameError as e:\n",
    "    if \"name 'df_sc_all' is not defined\" not in str(e):\n",
    "        raise\n",
    "else:\n",
    "    plot_horizontal_box_plots(\n",
    "        df=df_sc_all[[\"validation_scores\", \"test_score\", \"model_name\"]],\n",
    "        x=\"validation_scores\",\n",
    "        y=\"model_name\",\n",
    "        x2=\"test_score\",\n",
    "        plot_title=\"Comparison of Classifiers\",\n",
    "        marker_size=8,\n",
    "        scatter_marker_size=12,\n",
    "        marker_linewidth=1,\n",
    "        scatter_marker_linewidth=1,\n",
    "        marker_color=\"white\",\n",
    "        scatter_marker_color=\"darkred\",\n",
    "        edge_color=\"black\",\n",
    "        scatter_edge_color=\"black\",\n",
    "        xlabel=f\"{scoring_metric} Validation Scores\",\n",
    "        fig_size=(12, 9),\n",
    "        savefig=figs_dir_path,\n",
    "        save_pref=save_pref,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"export-experiment-outputs\"></a>\n",
    "\n",
    "## 11. [Export experiment outputs](#export-experiment-outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll append some columns to the `DataFrame`s of averaged and separate scores in order to summarize the conditions of the experiment. We'll export each of these `DataFrame`s to a separate `*.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cloud_data == \"no\":\n",
    "    export_experiment_results(\n",
    "        df_sc=df_sc,\n",
    "        df_sc_all=df_sc_all,\n",
    "        target_balance=target_balance,\n",
    "        nums=nums,\n",
    "        scoring_metric=scoring_metric,\n",
    "        experiment_summary_data_path=experiment_summary_data_path,\n",
    "        experiment_all_cv_data_path=experiment_all_cv_data_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"export-data-for-mapping\"></a>\n",
    "\n",
    "## 12. [Export data for mapping](#export-data-for-mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll use a helper function to retrieve the predicted label and prediction probability for the testing data, for a single user-specified model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll choose a single model and generate a summary of predictions and prediction probabilities for that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_probas(est, X_test, y_test, mapper_dict):\n",
    "    \"\"\"\n",
    "    Get prediction probabilities (if available) or return true and predicted\n",
    "    labels\n",
    "    \"\"\"\n",
    "    df_preds = pd.DataFrame(est.predict(X_test), index=X_test.index)\n",
    "    if hasattr(est.named_steps[\"clf\"], \"predict_proba\"):\n",
    "        # Get prediction probabilities (if available)\n",
    "        df_probas = pd.DataFrame(est.predict_proba(X_test), index=X_test.index)\n",
    "\n",
    "        # Append prediction and prediction probabilities\n",
    "        df_summ = pd.concat([df_preds, df_probas], axis=1)\n",
    "        df_summ.columns = [\"predicted_label\"] + [\n",
    "            f\"probability_of_{i}\" for i in range(0, len(np.unique(y_test)))\n",
    "        ]\n",
    "\n",
    "        # Get label (class) with maximum prediction probability for each row\n",
    "        df_summ[\"max_class_number_manually\"] = df_probas.idxmax(axis=1)\n",
    "        df_summ[\"probability_of_max_class\"] = df_probas.max(axis=1)\n",
    "\n",
    "        # Compare .predict_proba() and manually extracted prediction\n",
    "        # probability\n",
    "        if \"Dummy\" not in type(est.named_steps[\"clf\"]).__name__:\n",
    "            lhs = df_summ[\"max_class_number_manually\"]\n",
    "            rhs = df_summ[\"predicted_label\"].replace(mapper_dict)\n",
    "            assert (lhs == rhs).eq(True).all()\n",
    "    else:\n",
    "        df_summ = df_preds.copy()\n",
    "    # Get true label\n",
    "    df_summ.insert(0, \"true_label\", y_test)\n",
    "    return df_summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipe = get_best_pipe_by_model_name(\n",
    "    pipes_list=pipes_all, clf_name=\"LogisticRegression\"\n",
    ")\n",
    "\n",
    "df_summary = get_preds_probas(\n",
    "    est=best_pipe,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    mapper_dict=dict(zip(sorted(y_test.unique()), range(y_test.nunique()))),\n",
    ")\n",
    "df_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll merge these two predicted features to the testing data. Finally, we'll group the merged testing data, with predictions and prediction probabilities, in order to provide just enough data to the plotting notebook and to the dashboard file, so as to improve their respective plotting responsiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cloud_data == \"no\":\n",
    "    export_mapping_data(\n",
    "        df=df, X_test=X_test, df_summary=df_summary, d_mapping_specs=d_mapping_specs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.loc[X_test.index, nums + cats + [target]]\n",
    "assert df_test.shape[0] == X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"primary_type_pred\"] = best_pipe.predict(X_test)\n",
    "df_test[\"match\"] = df_test.apply(\n",
    "    lambda x: x[\"primary_type\"] in x[\"primary_type_pred\"], axis=1\n",
    ")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"location_description\",\n",
    "    \"community_area\",\n",
    "    \"domestic\",\n",
    "    \"arrest\",\n",
    "    \"is_weekend\",\n",
    "    \"is_dark\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"district\",\n",
    "    \"primary_type\",\n",
    "]\n",
    "xtick_angle = 15\n",
    "inter_plot_vertical_space = 1\n",
    "palette = \"bright\"\n",
    "fig_size = (15, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=fig_size, nrows=len(cols), ncols=1)\n",
    "plt.subplots_adjust(hspace=inter_plot_vertical_space)\n",
    "\n",
    "for ax, col in zip(axs, cols):\n",
    "    g = sns.barplot(\n",
    "        x=col,\n",
    "        y=\"latitude\",\n",
    "        data=df_test,\n",
    "        estimator=np.ma.count,\n",
    "        hue=\"match\",\n",
    "        palette=palette,\n",
    "        ci=None,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.grid(True)\n",
    "    ax.set_xticklabels(\n",
    "        ax.get_xticklabels(), rotation=xtick_angle, horizontalalignment=\"right\"\n",
    "    )\n",
    "    ax.set_xlabel(None)\n",
    "    ax.set_ylabel(None)\n",
    "    ax.set_title(\n",
    "        f\"Occurrences predicted correctly (True) and incorrectly (False), by {col.title().replace('_', ' ')}\",\n",
    "        fontweight=\"bold\",\n",
    "        loc=\"left\",\n",
    "    )\n",
    "    ax.tick_params(axis=\"x\", which=\"major\", pad=-5)\n",
    "    ax.tick_params(axis=\"y\", which=\"major\", pad=-5)\n",
    "    ax.legend(\n",
    "        loc=\"upper left\",\n",
    "        bbox_to_anchor=(1, 1),\n",
    "        framealpha=0,\n",
    "        handletextpad=0,\n",
    "        borderaxespad=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cloud_data == \"no\":\n",
    "    show_confusion_matrix(\n",
    "        est=best_pipe,\n",
    "        X_train=X_train_resampled,\n",
    "        y_train=y_train_resampled,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"examine-feature-importances\"></a>\n",
    "\n",
    "## 13. [Examine feature importances](#examine-feature-importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll train the best pipeline and use it to generate a plot of the feature importances or model coefficients, for the of `n` most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_st = time()\n",
    "\n",
    "dfi = get_feature_permutation_importances(\n",
    "    best_pipe=best_pipe,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    fig_size=(30, 90),\n",
    "    figs_dir_path=figs_dir_path,\n",
    "    save_pref=save_pref,\n",
    ")\n",
    "\n",
    "total_minutes, total_seconds = divmod(time() - cell_st, 60)\n",
    "print(\n",
    "    f\"Cell exection time: {int(total_minutes):d} minutes, {total_seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretations and Discussion**\n",
    "\n",
    "1. The four features that constitute the highest feature and permutation importances are\n",
    "   - domestic\n",
    "     - whether a crime involves domestic violence\n",
    "   - arrest\n",
    "     - whether a crime involves an arrest\n",
    "   - location decription\n",
    "     - the description of the location where the crime was committed\n",
    "   - district\n",
    "     - the Chicafo police district where the crime was committed\n",
    "2. Here, we will focus on the most frequently occurring sub-categories within each of these features\n",
    "   - The best model is relatively worse at making predictions where the crime did not involve domestic violence or an arrest. It shows greater accuracy at predicting where either of these are present and particularly so for crimes when the crime involves domestic violence. These two characteristics of recorded criminal events in this dataset have the highest feature and permutation importances.\n",
    "   - Crimes whose locations are described as public accessible or private housing have the largest number of occurrences and mis-classifications. Crimes committed on property adjoining public and private areas, but labeled in the data as one or the other, could account for some of this difficulty in the model classifying them separately. Private housing crimes have a higher permutation importance than crimes committed in publicly accessibile places and both have very low feature importances compared to less frequent location descriptions. Two less frequently occurring descriptions of the location of a crime - **business (academic)** and **dining/shopping** - have the highest feature and permutation importances of crime location descriptions. The model shows the same or worse [see business (academic)] accuracy at predicting crimes with these less frequent descriptions of the location where the crime was committed.\n",
    "   - [Police Districts](https://news.wttw.com/sites/default/files/Map%20of%20Chicago%20Police%20Districts%20and%20Beats.pdf) 1, 2, 3, 11, 12, 14, 18 and 19 have the highest occurrences of crime and also the largest number of mis-classifications by the best model. Simultaneously, these have the highest feature and permutation importances. These are neighboring districts within the North-Central part of the city. District 1 includes [Downtown Chicago](https://www.google.com/maps/place/Downtown+Chicago,+IL,+USA/@41.879198,-87.6389064,14z) and districts 2 and 3 are just south of Downtown. It is not surprising that the model subsequently struggles to classify crimes in the West Community Area (covering the center-west part of the city). Note that these districts are picked based on the total number of crimes committed and not based on a subset of crimes filtered by certain criteria. Future work should focus on improving model classification accuracy in these North-Central police districts.\n",
    "3. The best model is relatively better at classifying crimes that involve property damage than it does for less frequent crime types - criminal disturbances and crimes involving violence to humans. Due to the [class imbalance](https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-30164-8_110) problem mentioned earlier, more than half of each of the latter two types are being wrongly classified as property damage (the majority class) as seen from the confusion matrix. Future work could look into a combination of re-sampling and additional features can lead to an improvement here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
